---
layout: post
title: 协同过滤实战：网络小说推荐系统（二）
category: project
description: 基于用户和基于物品过滤算法的分别实现和利弊比较
---
项目源代码参见 [GitHub Repo](https://github.com/ZhiyuanLIPlus/EBooksRecommander)
## 算法
在完成了数据准备工作之后，我们就可以开始实施我们的协同过滤算法。在协同过滤推荐算法中，从算法实施方法上可以分成两种，一个是基于用户推荐，一个是是基于物品推荐。在这次项目里，因为代码上的工作量也不是很大，所以我分别实现了这两种算法并进行了比较。

### 度量方法
无论是基于用户过滤还是基于物品过滤，算法当中最重要的一部就是计算两位用户或者两个物品之间的相似度。
在这个项目里，我也是分别尝试了比较流行的三种方法作为度量标准。在每种计算的最后，我们都将计算出的相似性值缩放到[0, 1]的范围中，便于我们后面的计算。
[欧氏距离](https://en.wikipedia.org/wiki/Euclidean_distance "Euclidean distance")
[皮尔逊相关性系数](https://en.wikipedia.org/wiki/Pearson_correlation_coefficient "Pearson correlation coefficient")
[谷本系数](https://docs.tibco.com/pub/spotfire/6.5.3/doc/html/hc/hc_tanimoto_coefficient.htm "Tanimoto Coefficient")

### 基于用户过滤
基于用户过滤的算法步骤大致为：
1. 首先读取UserPrefs.txt中记录的个人偏好，以{书名：评分}的字典形式存储
2. 维护一张以{书名：总分}字典形式存储的总分字典和以{书名：加权值之和}字典形式存储的加权值之和字典。注：这里的加权值就是我们计算出来的相似度。
3. 遍历整理后数据集，依次计算数据集中每位用户和自己的相似性：
  1. 如果毫不相似或者负相似，我们直接跳过该用户
  2. 如果有相似，遍历该用户评过分的书籍，跳过已经被自己评过的小说。
    *. 对每一本小说，通过{估计评分 = 该用户评分 * 相似性} 计算该小说的估计评分，加进总分字典中
    *. 将相似性加进加权值之和字典中
4. 遍历总分字典，对字典中的每个小说进行计算 {最终评分 = 总分 / 加权值之和}
5. 对结果进行排序，输出结果

```
------------------ User Based: Sim Euclid --------------------
5.000000000000001:鹿鼎记
5.000000000000001:鸳鸯刀
5.000000000000001:飞狐外传
...
------------------ User Based: Sim Pearson --------------------
5.000000000000001:五代末年风云录
5.0:龙战骑士
5.0:鹿鼎记
...
------------------ User Based: Sim Tanimoto --------------------
5.000000000000001:龙的天空
5.000000000000001:都市之只手遮天
5.000000000000001:藏海花
...
------------------ User Based: Sim Tanimoto * 0.9 + Sim Euclid * 0.1 --------------------
5.000000000000001:贵圈真乱
5.000000000000001:汉末浮生记
5.000000000000001:欢乐英雄
...
```

这里只输出了每种算法的top3推荐，更多结果在[GitHub](https://github.com/ZhiyuanLIPlus/EBooksRecommander)上。

我们可以观察到，几乎每种推荐方法都给我们推荐了10+以上的我们可以打上5分(5分制)的小说。简单的分析一下数据集和算法，我们可以发现：
* 算法方面，在使用**欧氏距离**和**皮尔逊相关性**计算两个用户相似性时候，我们做的第一件事情就是计算两个用户共同打过分的小说。因为只有在共同打分的小说的基础上，这两种相似性度量计算才有意义。但是这样计算带来的问题是，如果用户A和用户B一共只有一本或者极少的共同打分项，而他们在这些极少共同项的打分上又恰好相同。这两种算法会认为这两位用户具有极高的为1的相似度。但是事实上并不一定如此。
* 对于计算交并集比例的Tanimoto系数，上面的问题并不存在。导致Tanimoto系数也出现这样无厘头结果的原因在于我的数据集。通过分析可以发现，我从优书网上抓取的数据集是一个十分典型的稀疏数据集。整个数据集大概包涵了9k多的用户数据和8k多的小说，这其中被大量用户共同评价过的小说的数量非常的少。在基于用户的过滤算法中，这样的稀疏数据集是很难有好的推荐效果的。
>   比如我们想给用户甲做推荐。通过计算，用户甲与用户乙的相似度为0.5，而用户乙给一本用户甲没有看过的小说A打了5分，而这本小说A也只有用户乙一个人打过分。那么在基于用户算法中，小说A的最终得分就会是{最终评分 = 5*0.5 / 0.5 = 5}。这显然是非常不合理的。
 
### 基于物品过滤
针对上面的问题，我又重新对数据集实现了基于物品的算法。步骤大致为：
1. 读取UserPrefs.txt中记录的个人偏好，以{书名：评分}的字典形式存储
2. 倒置存储数据集的嵌套字典，将{用户：{书名：评分}}的嵌套形式改为{书名：{用户：评分}}
```python
{
    'BookA':{
                'UserA': 3.5,
                'UserB': 5
            }
    'BookB':{
                'UserC': 2,
                'UserE': 1
            }
    #...etc..
}
```
3. 遍历数据集字典，对每本小说与其他小说进行相似性计算，对结果进行排序，选取其中前n个物品，以{ 书名: [(相似书名，相似性)*n] }的字典列表形式存储，因为这里的计算量十分大，我也在最后使用了pickle对计算结果序列化，下次重新推荐时候可以直接调用，避免重复计算。
4. 维护一张以{书名：总分}字典形式存储的总分字典和以{书名：加权值之和}字典形式存储的加权值之和字典。
5. 遍历个人偏好，对偏好中的每一本小说进行如下计算：
  * 遍历该小说的topN相似性字典，对其中的每一本小说通过{估计评分 = 个人偏好评分 * 相似性} 计算该小说的估计评分，加进总分字典中，也将相似性加进加权值之和字典中。
6. 遍历总分字典，对字典中的每个小说进行计算 {最终评分 = 总分 / 加权值之和}
7. 对结果进行排序，输出结果

```
------------------ Item Based: Sim Euclid --------------------
5.0:龙语实用教程
5.0:龙战骑士
5.0:龙人祖庭
4.75:鼠佛记
4.5:（新番完）何以笙箫默
4.5:龙魂武士

------------------ Item Based: Sim Tanimoto --------------------
5.0:江山美色
4.734782608695652:家园
4.733264675592173:二鬼子汉奸李富贵（曲线救国续集）
4.728716097928842:蚁贼
4.5882039942254265:1911新中华
4.5:文艺生活
4.5:好莱坞制作
4.5:一八九三
4.298245614035087:北唐
4.2900124366210655:原始战记
4.275614996977939:上品寒士
4.242975970425139:临高启明
4.219908363355485:新宋
4.11156323288314:一世之尊
4.091261182693812:回到过去变成猫

------------------ Item Based: Sim Pearson --------------------
5.0:龙域
5.0:重生亚当
5.0:近身保镖
4.5:龙骸
4.5:黑暗者
4.5:黑暗信仰

------------------ Item Based: Sim Tanimoto * 0.9 + Sim Euclid * 0.1 --------------------
5.0:白目老师
5.0:江山美色
5.0:大唐之我是独孤凤
5.0:夏鼎
5.0:全能炼金师
4.795960241853223:1911新中华
4.500000000000001:这个电影我穿过
```

可以清楚的看见，尽管皮尔逊和欧式距离的度量方法还是有很多同分情况，但是遍地5分的情况已经缓解了很多。而Tanimoto系数的表现更是出色。

## 小结
### 基于用户 vs 基于物品
#### 计算时间
在本次项目这个具体问题上，基于物品推荐的时间消耗是要远远大于基于用户推荐的，这也是为什么我在最后选择将计算结果序列化便于下次使用时候直接提取。
#### 推荐结果
对于我使用的稀疏数据集，毫无疑问，基于物品是要远远要优秀与基于用户推荐算法的。而其中Tanimoto系统算出的推荐列表更是有许多我其实已经看过，评价还不错但是忘了写进UserPrefs.txt中的小说。
#### Some Remarks
基于用户推荐的算法简单明了，易于理解而且实现过程也不复杂。应该更适用于那些规模较小，密集但是变化非常频繁的内存数据集。而且，在某些业务场景中，获取用户的偏好往往也具有更实际的意义。

基于物品推荐的算法则稍微复杂了一点。计算量也很大，对于稀疏数据集的性能远远大于基于用户推荐。但是，在初次计算结束将结果序列化或者存储之后如果数据集发生了较大或者频繁的变动，推荐结果很有可能会失真。而为了拥抱变化对topN的更新又需要耗费大量的时间。

### 度量方法
就像结果显示的那样，在这次项目中，Tanimoto系数的推荐效果是远远好于其他度量方法的。

第一个原因就像之前分析的那样，比较的Objects之间共有项太少导致其他度量很容易算出一个较高的相似度。Tanimoto系数就完全避免了这个问题。

另外，在数据来源方面，因为优书网是一个比较小众的网络文学评论网站。上面每个用户书单中的评分更多的像是推荐指数而不是对该小说的实际评分。这就导致了在一份书单中很容易出现大面积的5星评分。这给*欧氏距离**和**皮尔逊相关性**算法也带来了很多噪音。

因此，这样的数据其实也已经失去{评分}这个特征能够带来了计算意义。反而不如计算{看过小说A的所有用户与看过小说B的所有用户更容易重合}这样来的简单有效。

### 其他
算法这种东西果然是实施了具体项目之后才能有一个更深更全面的理解，也更有兴趣去学习啊。